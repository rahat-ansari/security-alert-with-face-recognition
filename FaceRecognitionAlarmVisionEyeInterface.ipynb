{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d9a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556291ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import face_recognition\n",
    "import torch\n",
    "import ultralytics\n",
    "print(f\"Dlib: {dlib.__version__}\")\n",
    "print(f\"Face-Recognition: {face_recognition.__version__}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Ultralytics: {ultralytics.__version__}\")\n",
    "\n",
    "import mediapipe\n",
    "print(f\"mediapipe: {mediapipe.__version__}\")\n",
    "\n",
    "import pygame\n",
    "print(f\"pygame: {pygame.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from numpy import source\n",
    "\n",
    "from ultralytics import solutions\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import pygame\n",
    "from ultralytics import solutions\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.solutions.config import SolutionConfig\n",
    "from ultralytics.utils import LOGGER\n",
    "\n",
    "from ultralytics.solutions.solutions import BaseSolution, SolutionAnnotator, SolutionResults\n",
    "from ultralytics.utils.plotting import colors\n",
    "\n",
    "# ========== üîä SOUND SETUP ==========\n",
    "pygame.mixer.init()\n",
    "ALARM_FILE = \"pols-aagyi-pols.mp3\"\n",
    "if os.path.exists(ALARM_FILE):\n",
    "    pygame.mixer.music.load(ALARM_FILE)\n",
    "else:\n",
    "    print(f\"[WARNING] Alarm file '{ALARM_FILE}' not found.\")\n",
    "\n",
    "\n",
    "# ========== üß† KNOWN FACE ENCODING LOADER ==========\n",
    "KNOWN_FACE_DIR = \"family_members\"\n",
    "known_face_encodings, known_face_names = [], []\n",
    "\n",
    "if os.path.exists(KNOWN_FACE_DIR):\n",
    "    for name in os.listdir(KNOWN_FACE_DIR):\n",
    "        person_dir = os.path.join(KNOWN_FACE_DIR, name)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "        for filename in os.listdir(person_dir):\n",
    "            path = os.path.join(person_dir, filename)\n",
    "            try:\n",
    "                img = face_recognition.load_image_file(path)\n",
    "                enc = face_recognition.face_encodings(img)\n",
    "                if enc:\n",
    "                    known_face_encodings.append(enc[0])\n",
    "                    known_face_names.append(name)\n",
    "                    print(f\"[INFO] Loaded face for {name} from {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Failed loading {path}: {e}\")\n",
    "else:\n",
    "    print(\"[WARNING] No known_faces directory found.\")\n",
    "\n",
    "\n",
    "# ========== üëÅÔ∏è FACE-RECOGNITION ALARM (REVISED & OPTIMIZED) ==========\n",
    "class FaceRecognitionAlarmVisionEye(solutions.VisionEye):\n",
    "    def __init__(self, *args, known_face_encodings=None, known_face_names=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.known_face_encodings = known_face_encodings or []\n",
    "        self.known_face_names = known_face_names or []\n",
    "        self.sound_played = False\n",
    "        # Best practice: Set face recognition tolerance during initialization\n",
    "        self.face_tolerance = 0.55\n",
    "        self.vision_point = self.CFG[\"vision_point\"]\n",
    "        self.records = self.CFG.get(\"records\", 1)\n",
    "        # self.show = self.CFG.get(\"show\", True)\n",
    "    \n",
    "    def play_sound(self):\n",
    "        \"\"\"Plays the alarm sound if it's not already playing.\"\"\"\n",
    "        if not self.sound_played:\n",
    "            if pygame.mixer.get_init() and not pygame.mixer.music.get_busy():\n",
    "                pygame.mixer.music.play()\n",
    "                self.sound_played = True\n",
    "                LOGGER.info(\"üö® Alarm Triggered: Unknown person count reached threshold.\")\n",
    "\n",
    "    def reset_sound(self):\n",
    "        \"\"\"Stops the alarm sound and resets the state.\"\"\"\n",
    "        if self.sound_played:\n",
    "            if pygame.mixer.get_init():\n",
    "                pygame.mixer.music.stop()\n",
    "            self.sound_played = False\n",
    "            LOGGER.info(\"üü¢ Alarm Reset: Area clear.\")\n",
    "\n",
    "    def __call__(self, im0):\n",
    "        \"\"\"\n",
    "        Processes a single frame for person detection and face recognition.\n",
    "        This implementation follows best practices for accuracy and performance.\n",
    "        \"\"\"\n",
    "        # 1. Get person detections from the base class\n",
    "        self.extract_tracks(im0)\n",
    "        annotator = SolutionAnnotator(im0, line_width=self.line_width)\n",
    "        \n",
    "        unknown_person_count = 0\n",
    "\n",
    "        # 2. Optimize by finding all faces in the frame at once (on a smaller version)\n",
    "        # This is much faster than processing crops for each person.\n",
    "        h, w, _ = im0.shape\n",
    "        small_frame = cv2.resize(im0, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        # 3. Iterate through detected PERSONS from YOLO\n",
    "        for box, conf, cls, t_id in zip(self.boxes, self.confs, self.clss, self.track_ids):\n",
    "            if int(cls) == 0:  # Skip if not a person\n",
    "                \n",
    "\n",
    "                name = \"Unknown\"\n",
    "                is_known = False\n",
    "                \n",
    "                # 4. Associate faces with person boxes\n",
    "                # Check if any detected face is inside this person's bounding box\n",
    "                person_box_left, person_box_top, person_box_right, person_box_bottom = map(int, box)\n",
    "                \n",
    "                for (face_top, face_right, face_bottom, face_left), face_encoding in zip(face_locations, face_encodings):\n",
    "                    # Scale face locations back to original image size\n",
    "                    face_top *= 4\n",
    "                    face_right *= 4\n",
    "                    face_bottom *= 4\n",
    "                    face_left *= 4\n",
    "\n",
    "                    # Check if the center of the face is inside the person's box\n",
    "                    face_center_x = (face_left + face_right) // 2\n",
    "                    face_center_y = (face_top + face_bottom) // 2\n",
    "\n",
    "                    if (person_box_left <= face_center_x <= person_box_right and\n",
    "                        person_box_top <= face_center_y <= person_box_bottom):\n",
    "                        \n",
    "                        # 5. Use robust face matching for the associated face\n",
    "                        if self.known_face_encodings:\n",
    "                            face_distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "                            best_match_index = np.argmin(face_distances)\n",
    "                            \n",
    "                            if face_distances[best_match_index] < self.face_tolerance:\n",
    "                                name = self.known_face_names[best_match_index]\n",
    "                                is_known = True\n",
    "                        \n",
    "                        # Once a face is matched to this person, stop checking other faces\n",
    "                        break \n",
    "                \n",
    "                # 6. Update counter and draw labels\n",
    "                if not is_known:\n",
    "                    unknown_person_count += 1\n",
    "                    color = (0, 0, 255) # Red for Unknown\n",
    "                    # label = f\"Unknown ({conf:.2f})\"\n",
    "                    label = f\"Unknown\"\n",
    "                else:\n",
    "                    color = (0, 255, 0) # Green for Known\n",
    "                    label = f\"{name}\"\n",
    "                    # label = f\"{name} ({conf:.2f})\"\n",
    "                \n",
    "                # annotator.box_label(box, label, color=color)\n",
    "                \n",
    "                # annotator.visioneye(box, self.vision_point)\n",
    "                # build base label from the existing adjust_box_label()\n",
    "                base_label = self.adjust_box_label(int(cls), float(conf) if conf is not None else 0.0, t_id)\n",
    "\n",
    "                # custom label for 'person' class (COCO id 0). Use CFG override if provided.\n",
    "                if int(cls) == 0:\n",
    "                    prefix = str(self.CFG.get(\"person_label_prefix\", label))\n",
    "                    custom_label = f\"{prefix}:\"\n",
    "                    # if base_label exists, concat both for full display\n",
    "                    final_label = f\"{custom_label} {base_label}\" if base_label else custom_label\n",
    "                else:\n",
    "                    final_label = base_label\n",
    "\n",
    "                # draw final label and vision eye mapping\n",
    "                annotator.box_label(box, label=final_label, color=colors(int(t_id), True))\n",
    "            else:\n",
    "                # For non-person classes, use default labeling\n",
    "                annotator.box_label(box, label=self.adjust_box_label(cls, conf, t_id), color=colors(int(t_id), True))\n",
    "            \n",
    "            annotator.visioneye(box, self.vision_point) \n",
    "\n",
    "        # 7. Trigger alarm based on the COUNT of unknown people and the 'records' threshold\n",
    "        if unknown_person_count >= self.records:\n",
    "            self.play_sound()\n",
    "        else:\n",
    "            self.reset_sound()\n",
    "\n",
    "        plot_im = annotator.result()\n",
    "        self.display_output(plot_im) \n",
    "        \n",
    "        \n",
    "        # Display track count on the frame\n",
    "        total_tracks = len(getattr(self, \"track_ids\", []))\n",
    "        cv2.putText(plot_im, f\"Tracks: {total_tracks}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        return SolutionResults(plot_im=plot_im, total_tracks=len(self.track_ids))\n",
    "\n",
    "   \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # cap = cv2.VideoCapture(0)\n",
    "    cap = cv2.VideoCapture(\"media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
    "    # cap = cv2.VideoCapture(\"media_files/person/ruhama/VID_20251122_142652.mp4\")\n",
    "    # cap = cv2.VideoCapture(\"media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "    # Video writer\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    video_writer = cv2.VideoWriter(\"visioneye_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    # Initialize vision eye object\n",
    "    visioneyeInterface = FaceRecognitionAlarmVisionEye(\n",
    "        show=True,  # display the output\n",
    "        model=\"yolo11m.pt\",  # use any model that Ultralytics support, i.e, YOLOv10\n",
    "        # classes=[0, 19],  # generate visioneye view for specific classes\n",
    "        vision_point=(550, 50),  # the point, where vision will view objects and draw tracks\n",
    "        known_face_encodings=known_face_encodings, \n",
    "        known_face_names=known_face_names,\n",
    "        records=3,\n",
    "        conf=0.5,\n",
    "        # show_labels=True,\n",
    "    )\n",
    "\n",
    " \n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    results = visioneyeInterface(im0)\n",
    "\n",
    "    print(results)  # access the output\n",
    "\n",
    "    # video_writer.write(results.plot_im)  # write the video file\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28331504",
   "metadata": {},
   "source": [
    "examaining above-given source code create a security surveillance alarm system app which can detect authorized person named image folder inside from the family_memembers folder other detected person count as threat with their susprecious activity or pose detection\n",
    "```\n",
    "# Consolidated, cleaned and runnable version of the notebook code.\n",
    "# Preserves comments and intent; fixes naming/type inconsistencies and unused imports.\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "from collections import defaultdict\n",
    "from numpy import ndarray\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the security system.\"\"\"\n",
    "    MODEL_PATH: str = \"yolo11n.pt\"\n",
    "    KNOWN_FACES_DIR: str = \"family_members\"\n",
    "    # use a neutral short filename to avoid word-checker flags\n",
    "    ALARM_FILE: str = \"pols-aagyi-pols.mp3\"\n",
    "    LOG_DIR: str = \"security_logs\"\n",
    "    VIDEO_SOURCE: str = 0  # camera index or path\n",
    "    FACE_RECOGNITION_INTERVAL: int = 5\n",
    "    ALERT_COOLDOWN: int = 10\n",
    "    YOLO_CONFIDENCE: float = 0.5\n",
    "    FACE_CONFIDENCE: float = 0.5\n",
    "    RESIZE_FACTOR: float = 0.25\n",
    "    WINDOW_NAME: str = \"Security Monitoring\"\n",
    "\n",
    "    OBJECTS_OF_INTEREST: List[str] = field(default_factory=lambda: [\n",
    "        \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"backpack\",\n",
    "        \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"cell phone\", \"laptop\",\n",
    "        \"book\", \"scissors\", \"knife\"\n",
    "    ])\n",
    "\n",
    "    # Stricter recognition controls to reduce false positives\n",
    "    RECOGNITION_MIN_VOTES: int = 2\n",
    "    RECOGNITION_DISTANCE_THRESHOLD: float = 0.45\n",
    "    RECOGNITION_CONSECUTIVE_FRAMES: int = 2\n",
    "    RECOGNITION_TIME_WINDOW: float = 3.0  # seconds\n",
    "\n",
    "class SecuritySystem:\n",
    "    \"\"\"\n",
    "    Enhanced security monitoring system with face recognition and object detection.\n",
    "\n",
    "    Features:\n",
    "    - Modular design with separate concerns\n",
    "    - Robust error handling\n",
    "    - Performance optimizations\n",
    "    - Comprehensive logging\n",
    "    - Configurable parameters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.logger = self._setup_logging()\n",
    "\n",
    "        # Models and resources\n",
    "        self.yolo_model: Optional[YOLO] = None\n",
    "        self.mp_face_detection = None\n",
    "        self.known_face_encodings: List[ndarray] = []\n",
    "        self.known_face_names: List[str] = []\n",
    "        self.alarm_loaded = False\n",
    "\n",
    "        # State\n",
    "        self.frame_count = 0\n",
    "        self.last_alert_time = 0.0\n",
    "\n",
    "        # Per-person detection history to reduce false positives\n",
    "        # { person_id: { 'name_counts': defaultdict(int), 'last_name': str, 'consecutive': int, 'last_update': float } }\n",
    "        self.detection_history: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "        # Initialize heavy resources\n",
    "        self._initialize_resources()\n",
    "\n",
    "    def _setup_logging(self) -> logging.Logger:\n",
    "        logger = logging.getLogger('SecuritySystem')\n",
    "        if not logger.handlers:\n",
    "            logger.setLevel(logging.INFO)\n",
    "            os.makedirs(self.config.LOG_DIR, exist_ok=True)\n",
    "            log_file = os.path.join(self.config.LOG_DIR, f\"security_log_{datetime.now().strftime('%Y-%m-%d')}.txt\")\n",
    "            fh = logging.FileHandler(log_file)\n",
    "            fh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(fh)\n",
    "            sh = logging.StreamHandler()\n",
    "            sh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(sh)\n",
    "        return logger\n",
    "\n",
    "    def _initialize_resources(self) -> None:\n",
    "        try:\n",
    "            self.logger.info(\"Loading YOLO model...\")\n",
    "            self.yolo_model = YOLO(self.config.MODEL_PATH)\n",
    "\n",
    "            self.logger.info(\"Initializing MediaPipe face detection...\")\n",
    "            mp_face = mp.solutions.face_detection\n",
    "            self.mp_face_detection = mp_face.FaceDetection(\n",
    "                model_selection=0,\n",
    "                min_detection_confidence=self.config.FACE_CONFIDENCE\n",
    "            )\n",
    "\n",
    "            self._load_known_faces()\n",
    "            self._setup_alarm()\n",
    "\n",
    "            self.logger.info(\"System initialization completed successfully\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to initialize resources: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _load_known_faces(self) -> None:\n",
    "        \"\"\"Load known faces from directory with error handling.\"\"\"\n",
    "        if not os.path.exists(self.config.KNOWN_FACES_DIR):\n",
    "            self.logger.warning(f\"Known faces directory {self.config.KNOWN_FACES_DIR} not found\")\n",
    "            return\n",
    "\n",
    "        for person_name in os.listdir(self.config.KNOWN_FACES_DIR):\n",
    "            person_dir = os.path.join(self.config.KNOWN_FACES_DIR, person_name)\n",
    "            if not os.path.isdir(person_dir):\n",
    "                continue\n",
    "            for image_name in os.listdir(person_dir):\n",
    "                image_path = os.path.join(person_dir, image_name)\n",
    "                try:\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    encodings = face_recognition.face_encodings(image)\n",
    "                    if encodings:\n",
    "                        self.known_face_encodings.append(encodings[0])\n",
    "                        self.known_face_names.append(person_name)\n",
    "                        self.logger.info(f\"Loaded face: {person_name} from {image_name}\")\n",
    "                    else:\n",
    "                        self.logger.warning(f\"No faces found in {image_path}\")\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error loading {image_path}: {e}\")\n",
    "\n",
    "        unique_people = len(set(self.known_face_names))\n",
    "        self.logger.info(f\"Loaded {len(self.known_face_encodings)} face encodings for {unique_people} people\")\n",
    "\n",
    "    def _setup_alarm(self) -> None:\n",
    "        \"\"\"Setup alarm sound system.\"\"\"\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            if os.path.exists(self.config.ALARM_FILE):\n",
    "                pygame.mixer.music.load(self.config.ALARM_FILE)\n",
    "                self.alarm_loaded = True\n",
    "                self.logger.info(\"Alarm system initialized\")\n",
    "            else:\n",
    "                self.logger.warning(f\"Alarm file {self.config.ALARM_FILE} not found\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to setup alarm: {e}\")\n",
    "\n",
    "    def detect_objects(self, frame: ndarray) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Detect objects using YOLO model and return normalized detections.\"\"\"\n",
    "        if not self.yolo_model:\n",
    "            return []\n",
    "        try:\n",
    "            results = self.yolo_model(frame, imgsz=640, verbose=False)\n",
    "            detections: List[Dict[str, Any]] = []\n",
    "            for result in results:\n",
    "                if getattr(result, \"boxes\", None) is None:\n",
    "                    continue\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cls = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    class_name = result.names[cls] if hasattr(result, \"names\") else str(cls)\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        continue\n",
    "                    detections.append({\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'class_name': class_name,\n",
    "                        'confidence': conf,\n",
    "                        'class_id': cls\n",
    "                    })\n",
    "            return detections\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Object detection failed: {e}\")\n",
    "            return []\n",
    "\n",
    "    def detect_faces_mediapipe(self, roi: ndarray) -> List[Tuple[int, int, int, int]]:\n",
    "        \"\"\"Detect faces in a region of interest using MediaPipe and return list of (x,y,w,h).\"\"\"\n",
    "        try:\n",
    "            rgb_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            results = self.mp_face_detection.process(rgb_roi)\n",
    "            face_boxes: List[Tuple[int, int, int, int]] = []\n",
    "            if results and getattr(results, \"detections\", None):\n",
    "                h, w = roi.shape[:2]\n",
    "                for detection in results.detections:\n",
    "                    bbox = detection.location_data.relative_bounding_box\n",
    "                    x = int(bbox.xmin * w)\n",
    "                    y = int(bbox.ymin * h)\n",
    "                    width = int(bbox.width * w)\n",
    "                    height = int(bbox.height * h)\n",
    "                    face_boxes.append((x, y, width, height))\n",
    "            return face_boxes\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Face detection failed: {e}\")\n",
    "            return []\n",
    "\n",
    "    def recognize_face(self, face_roi: ndarray) -> Optional[str]:\n",
    "        \"\"\"Recognize face in given ROI; returns known name or 'Unknown' or None on failure.\"\"\"\n",
    "        try:\n",
    "            if not self.known_face_encodings:\n",
    "                return None\n",
    "            small_roi = cv2.resize(face_roi, (0, 0), fx=self.config.RESIZE_FACTOR, fy=self.config.RESIZE_FACTOR)\n",
    "            rgb_small = cv2.cvtColor(small_roi, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb_small)\n",
    "            if not face_locations:\n",
    "                return None\n",
    "            encodings = face_recognition.face_encodings(rgb_small, face_locations)\n",
    "            if not encodings:\n",
    "                return None\n",
    "            for enc in encodings:\n",
    "                matches = face_recognition.compare_faces(self.known_face_encodings, enc)\n",
    "                distances = face_recognition.face_distance(self.known_face_encodings, enc)\n",
    "                if len(distances) == 0:\n",
    "                    continue\n",
    "                best_index = int(np.argmin(distances))\n",
    "                if matches and matches[best_index]:\n",
    "                    return self.known_face_names[best_index]\n",
    "            return \"Unknown\"\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Face recognition failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Robust recognition helpers (vote-based) to reduce false positives\n",
    "    def _get_person_id(self, bbox: Tuple[int, int, int, int]) -> str:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cx = (x1 + x2) // 2\n",
    "        cy = (y1 + y2) // 2\n",
    "        return f\"{cx//50}_{cy//50}\"\n",
    "\n",
    "    def _update_detection_history(self, person_id: str, name: str, distance: float) -> None:\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if entry is None:\n",
    "            entry = {\n",
    "                'name_counts': defaultdict(int),\n",
    "                'last_name': None,\n",
    "                'consecutive': 0,\n",
    "                'last_update': now\n",
    "            }\n",
    "            self.detection_history[person_id] = entry\n",
    "\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            entry['name_counts'] = defaultdict(int)\n",
    "            entry['last_name'] = None\n",
    "            entry['consecutive'] = 0\n",
    "\n",
    "        entry['name_counts'][name] += 1\n",
    "        if entry['last_name'] == name:\n",
    "            entry['consecutive'] += 1\n",
    "        else:\n",
    "            entry['last_name'] = name\n",
    "            entry['consecutive'] = 1\n",
    "        entry['last_update'] = now\n",
    "\n",
    "    def _confirm_recognition(self, person_id: str, name: str, distance: float) -> bool:\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if not entry:\n",
    "            return False\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            return False\n",
    "        if name != \"UNKNOWN\" and distance <= self.config.RECOGNITION_DISTANCE_THRESHOLD:\n",
    "            return True\n",
    "        votes = entry['name_counts'].get(name, 0)\n",
    "        if name != \"UNKNOWN\" and votes >= self.config.RECOGNITION_MIN_VOTES:\n",
    "            return True\n",
    "        if name != \"UNKNOWN\" and entry['consecutive'] >= self.config.RECOGNITION_CONSECUTIVE_FRAMES:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def confirm_face(self, face_encoding: ndarray, bbox: Tuple[int, int, int, int]) -> Tuple[Optional[str], bool, Optional[float]]:\n",
    "        \"\"\"Return (name_or_None, confirmed_bool, distance_or_None).\"\"\"\n",
    "        if not self.known_face_encodings:\n",
    "            return None, False, None\n",
    "        try:\n",
    "            distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"face_distance failed: {e}\")\n",
    "            return None, False, None\n",
    "        if distances is None or len(distances) == 0:\n",
    "            return None, False, None\n",
    "        best_idx = int(np.argmin(distances))\n",
    "        best_dist = float(distances[best_idx])\n",
    "        candidate_name = self.known_face_names[best_idx] if best_dist <= self.config.FACE_CONFIDENCE else \"UNKNOWN\"\n",
    "        person_id = self._get_person_id(bbox)\n",
    "        self._update_detection_history(person_id, candidate_name, best_dist)\n",
    "        confirmed = self._confirm_recognition(person_id, candidate_name, best_dist)\n",
    "        if confirmed and candidate_name != \"UNKNOWN\":\n",
    "            return candidate_name, True, best_dist\n",
    "        return None, False, best_dist\n",
    "\n",
    "    def draw_detections(self, frame: ndarray, detections: List[Dict[str, Any]], person_results: List[Dict[str, Any]]) -> ndarray:\n",
    "        \"\"\"Draw detection results on frame.\"\"\"\n",
    "        display = frame.copy()\n",
    "        for det in detections:\n",
    "            if det['class_name'] in self.config.OBJECTS_OF_INTEREST and det['class_name'] != \"person\":\n",
    "                x1, y1, x2, y2 = det['bbox']\n",
    "                cv2.rectangle(display, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                label = f\"{det['class_name']}: {det['confidence']:.2f}\"\n",
    "                cv2.putText(display, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "\n",
    "        for person in person_results:\n",
    "            x1, y1, x2, y2 = person['bbox']\n",
    "            color = (0, 255, 0) if person.get('recognized') else (0, 165, 255)\n",
    "            cv2.rectangle(display, (x1, y1), (x2, y2), color, 2)\n",
    "            label = person.get('name', 'Person') if person.get('recognized') else \"UNKNOWN\"\n",
    "            cv2.putText(display, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            for fx, fy, fw, fh in person.get('face_boxes', []):\n",
    "                cv2.rectangle(display, (x1 + fx, y1 + fy), (x1 + fx + fw, y1 + fy + fh), (255, 0, 0), 2)\n",
    "                cv2.putText(display, \"Face\", (x1 + fx + 5, y1 + fy - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        return display\n",
    "\n",
    "    def process_alert(self, person_name: str, detected_objects: List[str], is_known: bool) -> None:\n",
    "        \"\"\"\n",
    "        Handle alert logic with cooldown.\n",
    "        Only triggers alarm sound for unknown persons (is_known == False).\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_alert_time <= self.config.ALERT_COOLDOWN:\n",
    "            # still in cooldown\n",
    "            return\n",
    "\n",
    "        # Only trigger alert for unknown persons to avoid false alarms for known people\n",
    "        if not is_known:\n",
    "            self._trigger_alert(person_name, detected_objects, is_known=False)\n",
    "            self.last_alert_time = current_time\n",
    "        else:\n",
    "            # Log known person detection but do not play alarm\n",
    "            self.logger.info(f\"Known person '{person_name}' detected. No alarm triggered.\")\n",
    "\n",
    "    def _trigger_alert(self, person_name: str, detected_objects: List[str], is_known: bool) -> None:\n",
    "        \"\"\"\n",
    "        Trigger alert mechanisms.\n",
    "        Plays alarm only when is_known is False.\n",
    "        \"\"\"\n",
    "        objects_str = \", \".join(set(detected_objects)) if detected_objects else \"None\"\n",
    "        if is_known:\n",
    "            # Do not play alarm for verified known persons\n",
    "            self.logger.info(f\"ALERT(Logged only): Known person {person_name} detected with objects: {objects_str}\")\n",
    "            return\n",
    "\n",
    "        # Unknown person -> play alarm and log\n",
    "        self.logger.info(f\"ALERT: UNKNOWN person detected with objects: {objects_str}\")\n",
    "        try:\n",
    "            if self.alarm_loaded and not pygame.mixer.music.get_busy():\n",
    "                pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to play alarm: {e}\")\n",
    "\n",
    "    def process_frame(self, frame: ndarray) -> ndarray:\n",
    "        self.frame_count += 1\n",
    "        timer = cv2.getTickCount()\n",
    "        detections = self.detect_objects(frame)\n",
    "        person_detections = [d for d in detections if d['class_name'] == 'person']\n",
    "        detected_objects = [d['class_name'] for d in detections if d['class_name'] in self.config.OBJECTS_OF_INTEREST and d['class_name'] != 'person']\n",
    "\n",
    "        person_results: List[Dict[str, Any]] = []\n",
    "        process_faces = (self.frame_count % self.config.FACE_RECOGNITION_INTERVAL) == 0\n",
    "\n",
    "        for det in person_detections:\n",
    "            x1, y1, x2, y2 = det['bbox']\n",
    "            person_roi = frame[y1:y2, x1:x2]\n",
    "            result = {'bbox': (x1, y1, x2, y2), 'recognized': False, 'name': None, 'face_boxes': []}\n",
    "            if person_roi.size > 0:\n",
    "                face_boxes = self.detect_faces_mediapipe(person_roi)\n",
    "                result['face_boxes'] = face_boxes\n",
    "                if process_faces and face_boxes:\n",
    "                    # attempt recognition from the first face region for speed\n",
    "                    # fx, fy, fw, fh = face_boxes[0]\n",
    "                    # face_crop = person_roi[fy:fy+fh, fx:fx+fw]\n",
    "                    # name = self.recognize_face(face_crop)\n",
    "                    # if name:\n",
    "                    #     result['recognized'] = (name != \"Unknown\")\n",
    "                    #     result['name'] = name if name != \"Unknown\" else None\n",
    "                    #     if result['recognized'] and name:\n",
    "                    #         self.process_alert(name, detected_objects, is_known=True)\n",
    "                    #     else:\n",
    "                    #         self.process_alert(name, detected_objects, is_known=False)   \n",
    "                    fx, fy, fw, fh = face_boxes[0]\n",
    "                    # clamp coordinates to ROI bounds\n",
    "                    h_roi, w_roi = person_roi.shape[:2]\n",
    "                    x0 = max(0, fx); y0 = max(0, fy)\n",
    "                    x1 = min(w_roi, fx + fw); y1 = min(h_roi, fy + fh)\n",
    "                    if x1 > x0 and y1 > y0:\n",
    "                        face_crop = person_roi[y0:y1, x0:x1]\n",
    "                        name = self.recognize_face(face_crop)\n",
    "                        # if recognition failed (None), skip alerting\n",
    "                        if name is None:\n",
    "                            pass\n",
    "                        else:\n",
    "                            result['recognized'] = (name != \"Unknown\")\n",
    "                            result['name'] = name if name != \"Unknown\" else None\n",
    "                            self.process_alert(name, detected_objects, is_known=result['recognized']) \n",
    "            person_results.append(result)\n",
    "\n",
    "        annotated = self.draw_detections(frame, detections, person_results)\n",
    "        elapsed = max(1, cv2.getTickCount() - timer)\n",
    "        fps = int(cv2.getTickFrequency() / elapsed)\n",
    "        cv2.putText(annotated, f\"FPS: {fps}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        if detected_objects:\n",
    "            cv2.putText(annotated, f\"Objects: {', '.join(set(detected_objects))}\", (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        return annotated\n",
    "    \n",
    "    def run(self) -> None:\n",
    "        cap = cv2.VideoCapture(self.config.VIDEO_SOURCE)\n",
    "        if not cap.isOpened():\n",
    "            self.logger.error(\"Could not open video capture device\")\n",
    "            raise RuntimeError(\"Video capture failed\")\n",
    "        self.logger.info(\"Security monitoring started. Press 'q' to quit.\")\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    self.logger.warning(\"Failed to grab frame\")\n",
    "                    break\n",
    "                annotated = self.process_frame(frame)\n",
    "                cv2.imshow(self.config.WINDOW_NAME, annotated)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Monitoring interrupted by user\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Runtime error: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            self._cleanup(cap)\n",
    "\n",
    "    def _cleanup(self, cap) -> None:\n",
    "        try:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            if self.mp_face_detection:\n",
    "                self.mp_face_detection.close()\n",
    "            pygame.mixer.quit()\n",
    "            self.logger.info(\"System shutdown completed\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Cleanup error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    system = SecuritySystem(cfg)\n",
    "    system.run()  # uncomment to run live monitoring\n",
    "``` \n",
    "/help me to improve and optimize code according to best practice and suggest standrad fesible FACE_RECOGNITION_INTERVAL along with inconsistacy also consider along with above concerns please review and fix for confirming false alarm for the known person\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV_SECURITY_ALERT_YOLO_FACE_RE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
